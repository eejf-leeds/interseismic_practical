{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"643e5e76","cell_type":"markdown","source":"<img src=\"figures/logos.png\" style=\"float: centre;\" width=\"800\"/>\n\n# Interseismic practical\n\n## Written for the COMET InSAR Workshop 2024.\n\nWelcome to this COMET practical on interseismic strain accumulation.\n\nThis practical has been tested in the latest versions of Chrome and Firefox, but should work in most modern browsers.\n\n### Interacting with this practical\n\nTo run a cell containing code, you can either press \"Run\" in the bar above, or press \"Shift+Enter\".\n\nA \"#\" indicates a comment within the code. \n\n##################################### <br />\nBlocks of code surrounded by multiple \"#\" (like this one) indicate variables that you can experiment changing the values to. While you can experiment with the full body of code further (and I encourage you to do so after the course), we are limited in our ability to help you debug any errors you may encounter. Changing just the values indicate should result in no major errors. <br />\n#####################################\n\nIf you get a \"dead kernel\" error, either restart the kernel under \"Kernel\" on the top bar, or reopen the binder fresh. None of your changes here will affect the original binder, so feel free to reload it if anything breaks.\n\n### Acknowledgements\nDetailed guidance on the content was provided by [John Elliott](https://environment.leeds.ac.uk/see/staff/1248/dr-john-elliott). Advice on the computational requirements of the practical was provided by [Richard Rigby](https://environment.leeds.ac.uk/see/staff/2698/richard-rigby). This notebook was written by [Andrew Watson](https://www.linkedin.com/in/andrew-watson-a5248b1aa/?originalSubdomain=uk) using resources from the Tectonophysics ([Tim Wright](https://environment.leeds.ac.uk/see/staff/1613/professor-tim-wright)) and Inverse Theory ([Phil Livermore](https://environment.leeds.ac.uk/see/staff/1381/dr-phil-livermore)) undergraduate modules at the University of Leeds. The strain rate sections were written by, and with the help of, [Qi Ou](https://environment.leeds.ac.uk/see/staff/11006/dr-qi-ou). Thanks to everyone for their contributions.\n\n[Andrew Watson](https://github.com/andwatson), [Qi Ou](https://environment.leeds.ac.uk/see/staff/11006/dr-qi-ou), [John Condon](https://www.linkedin.com/in/john-condon-216268134/?originalSubdomain=uk) - 2024\n\nPresenter: Dehua Wang (E-mail: eedwa@leeds.ac.uk), University of Leeds","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"id":"8b632279","cell_type":"code","source":"# Import required modules. Run this before continuing.\n\n# these are for performing the analysis\nimport numpy as np\nfrom scipy import interpolate\nfrom scipy import stats\nfrom scipy import ndimage\nimport statistics\nimport pyproj\nimport subprocess as subp\nfrom pathlib import Path\n# this is our own library of functions, which can be found in the same directory as this notebook\nimport interseis_lib as lib\n\n# this package is for general plotting\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n# this is additional scientific colour maps, see \"https://www.fabiocrameri.ch/colourmaps/\"\nfrom cmcrameri import cm\n\n# these packages are only needed for the final multivariate plot\nimport seaborn as sns\nimport pandas as pd\n\n# this package is only needed for the strain rate calculation in the extension\nimport pygmt\n\n# this refreshes the import of interseis_lib if changes are made while the notebook is running\nimport importlib\nimportlib.reload(lib)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3f27112b","cell_type":"markdown","source":"## 0. Introduction\n\nThe earthquake cycle is a model for how earthquakes occur on faults. It consists of three phases:\n- **Interseismic** - the fault is locked towards the surface but is accumulating strain at depth driven by external forces (i.e. plate motion).\n- **Coseismic** - the strain is released seismically by slip on the previously-locked section of the fault.\n- **Postseismic** - mechanisms after the earthquake such as afterslip or viscoelastic relaxation.\n\nWe'll be focusing on the interseismic period for this practical. Figure 1 shows a schematic diagram of how the ground deforms through the interseismic period (middle panel) and into the coseismic (right panel). Profile A-A' shows a characteristic interseismic signal in the middle panel (the shape of an arctan function), where the ground displacement decreases from the far-field to zero at the fault trace.\n\n<img src=\"figures/earthquakeCycle.png\" style=\"float: centre;\" width=\"600\"/>\n\n*Figure 1: Schematic map diagram of how expected ground deformation through the interseismic and coseismic periods. From Elliott (2009).*\n\nGeodesists are interested in this interseismic period as it provides information on the rate of strain accumulation and the size of the locked part of the fault, important parameters for understanding the seismic potential of a fault and the distribution of strain in the crust.\n\nWe can model interseismic deformation by considering steady slip on a screw dislocation embedded within an elastic half-space (Savage and Burford, 1973, Wright et al., 2013). In this simple model, the fault-parallel surface velocities, $v$, are a function of the perpendicular distance from the fault, $x$, the slip rate, $s$, and the locking depth, $d$:\n\n\\begin{equation}\n\\normalsize v(x) = \\frac{s}{\\pi}tan^{-1}\\left(\\frac{x}{d}\\right) + c \\qquad \\qquad (1)\n\\end{equation}\n\nFigure 2 shows a schematic diagram of this screw dislocation model.\n\n<img src=\"figures/screwDisc.png\" style=\"float: centre;\" width=\"600\"/>\n\n*Figure 2: Schematic diagram of a screw dislocation model. Reproduced from Vernant (2015).*\n\nLarge volumes of InSAR data have been processed over the North Anatolian Fault (NAF) in Turkey by LiCS. We'll be using two of these LiCSBAS time series (087A_04904_121313 and 167D_04884_131212, shown in Figure 3) to estimate fault-parallel velocities, which we will then use to estimate the values of the parameters in Equation 1.\n\n<img src=\"figures/frameMap.png\" style=\"float: centre;\" width=\"600\"/>\n\n*Figure 3: Location of our two LiCS frames overlayed on faults (red lines) from the Global Earthquake Model (https://github.com/GEMScienceTools/gem-global-active-faults).*\n\nThis practical is broken down into the following sections:\n\n**1)** Generating a simple synthetic screw dislocation model and investigating what we might expect InSAR to measure.\n\n**2)** Loading in our LiCSBAS velocities and other data files.\n\n**3)** Decomposing our two line-of-sight velocity maps into both East and vertical velocities, under the assumption of zero North velocity, and into fault-parallel and vertical velocities, under the assumption of zero fault-perpendicular velocity. This includes resampling our velocities onto a unified grid and setting a common reference point.\n\n**4)** Projecting the fault-parallel velocities onto a fault-perpendicular profile.\n\n**5)** Performing a forward model to explore our profiled velocities.\n\n**6)** Incorporation of surface fault creep in our model.\n\n**7)** Estimating shear strain rate from 1-D velocity profiles\n\n**8)** Estimating strain rates from 2-D surface velocities.\n\n**9)** Extension - Performing a Bayesian inversion to estimate the parameters in Equation 1, along with their associated uncertainties.\n\n\nFor an example of this general method, have a look at our paper on the Main Recent Fault, Iran:\nhttps://doi.org/10.1029/2021JB022674","metadata":{}},{"id":"6c7b453b","cell_type":"markdown","source":"## 1. Synthetic screw dislocation model\n\nWe'll start by generating some synthetic velocities using our screw dislocation model.","metadata":{}},{"id":"b06b20d0","cell_type":"code","source":"import interseis_lib as lib\n\n# set interseismic fault slip rate, s, and locking depth, d\n#####################################\ns = 20 # mm/yr          \nd = 20 # km             \n#####################################\n\n# set up x coords (fault-perpendicular distances from -200 km to 200 km, with a sample every 2 km)\nx = np.arange(-200, 202, 2)\n\n# run the screw dislocation model. The 0 is just a static offset which we can ignore for now.\n# We convert all units into SI (metres) so that they are consistent.\nv = lib.screw_disc(x*1000, s/1000, d*1000, 0)\n\n# expand into 2D, assuming our fault strikes East-West\nv_grid = np.tile(v, (len(x),1)).T\n\n# we'll also generate a model at s = 10 mm/yr and d = 10 km as a reference solution \n# so that you can see how changing s and d could affect the shape of the arctangent profile.\ns_ref = 10 # mm/yr\nd_ref = 10 # km\nv_ref = lib.screw_disc(x*1000, s_ref/1000, d_ref*1000, 0)\n\n# Plot the result\nlib.plot_screw_disc(x, s, d, v, s_ref, d_ref, v_ref, v_grid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d8ac46c0","cell_type":"markdown","source":"The left plot shows our simple 1D screw dislocation model. The right shows this model expanded to 2D, assuming that our fault strikes from East to West. The fault-parallel velocities are also East-West velocities in this setup.\n\nWhile these fault-parallel velocities are what we want for modelling a fault, they're not what we directly measure with InSAR. SAR satellites such as Sentinel-1 look down at the ground with an incidence angle, $\\theta$, of around 31-46&deg;. This angle changes through our scene. InSAR is also only capable of measuring displacements towards and away from the satellite. The result of these two factors is that InSAR measures only a component of the observed deformation projected into the satellite's line-of-sight (LOS), and a single look direction cannot differentiate between different components of displacement.\n\n<img src=\"figures/incAngle.png\" style=\"float: centre;\" width=\"300\"/>\n\n*Figure 4: Schematic diagram of satellite incidence angle, $\\theta$, measured between the vertical (dashed black line) and the satellite line-of-sight (blue arrow).*\n\nLet's apply a line-of-sight projection to our signals and see what effect this has on the velocities.\n\nThe interseismic_lib includes a function to make a grid of incidence angles between a minimum and maximum value, rotated by the satellite heading. Remember that the Sentinel-1 satellites are side looking, so our incidence angles will change at 90&deg; to the satellite heading.","metadata":{}},{"id":"5b82da7c","cell_type":"code","source":"# heading (-14 for ascending, -166 for descending), minimum incidence angle, and maximum incidence angle\n#####################################\nheading = -14 # degrees\ninc_min, inc_max = 31, 46 # degrees\n#####################################\n\n# create grids of these angles\nheading_grid = np.ones(v_grid.shape) * heading\ninc_grid = lib.gen_inc(inc_min, inc_max, heading, x, x)\n\n# projection from east-west to los\ne2los = np.cos(np.deg2rad(heading_grid)) * np.sin(np.deg2rad(inc_grid))\nv_grid_los = v_grid * e2los\n\n# plot the 2D los and see how the incidence angle variation in range direction \n# changes the fault perpendicular velocity variation in the line of sight\nlib.plot_screw_disc_in_los(x, v, inc_grid, v_grid, v_grid_los)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c3b8e89c","cell_type":"markdown","source":"We can see that not only does the overall signal get smaller, but it also changes across the scene because of the varying incidence angle of the satellite.\n\nNow that we've explored how a screw dislocation model might look in InSAR, we'll move on to applying the model to real world data.","metadata":{}},{"id":"d03452a4","cell_type":"markdown","source":"## 2. Load the input line-of-sight velocities\n\nWe'll begin by loading in our LiCSBAS outputs (you generated the equivalent outputs in the LiCSBAS practicals). These have been renamed to include the frame name for clarity. The _asc and _desc tags in the variable names indicate the ascending or descending frame.\n\n**vel_file** - file containing the LOS velocities (found in TS_GEOCml10/results/vel).\n\n**par_file** - parameter file which contains the geographic location of the data, along with the size in x and y (found in GEOCml##).\n\n**E/N/U_file** - unit vector components, which basically tell us how to go from the satellite LOS to East, North, and Up. We need these to perform the velocity decomposition later.","metadata":{}},{"id":"5cbe832d","cell_type":"code","source":"# setup file names\nasc = '087A_04904_121313'\ndesc = '167D_04884_131212'\n\nvel_file_asc = Path('data/' + asc + '.vel.mskd')\npar_file_asc = Path('data/' + asc + '.par')\nE_file_asc = Path('data/' + asc + '.E')\nN_file_asc = Path('data/' + asc + '.N')\nU_file_asc = Path('data/' + asc + '.U')\n\nvel_file_desc = Path('data/' + desc + '.vel.mskd')\npar_file_desc = Path('data/' + desc + '.par')\nE_file_desc = Path('data/' + desc + '.E')\nN_file_desc = Path('data/' + desc + '.N')\nU_file_desc = Path('data/' + desc + '.U')\n\n# read array dimensions from par file\nwidth_asc = int(lib.get_par(par_file_asc,'width'))\nlength_asc = int(lib.get_par(par_file_asc,'nlines'))\n\nwidth_desc = int(lib.get_par(par_file_desc,'width'))\nlength_desc = int(lib.get_par(par_file_desc,'nlines'))\n\n# get corner positions\ncorner_lat_asc = float(lib.get_par(par_file_asc,'corner_lat'))\ncorner_lon_asc = float(lib.get_par(par_file_asc,'corner_lon'))\n\ncorner_lat_desc = float(lib.get_par(par_file_desc,'corner_lat'))\ncorner_lon_desc = float(lib.get_par(par_file_desc,'corner_lon'))\n\n# get post spacing (distance between velocity measurements)\npost_lat_asc = float(lib.get_par(par_file_asc,'post_lat'))\npost_lon_asc = float(lib.get_par(par_file_asc,'post_lon'))\n\npost_lat_desc = float(lib.get_par(par_file_desc,'post_lat'))\npost_lon_desc = float(lib.get_par(par_file_desc,'post_lon'))\n\n# calculate grid spacings\nlat_asc = corner_lat_asc + post_lat_asc*np.arange(1,length_asc+1) - post_lat_asc/2\nlon_asc = corner_lon_asc + post_lon_asc*np.arange(1,width_asc+1) - post_lon_asc/2\n\nlat_desc = corner_lat_desc + post_lat_desc*np.arange(1,length_desc+1) - post_lat_desc/2\nlon_desc = corner_lon_desc + post_lon_desc*np.arange(1,width_desc+1) - post_lon_desc/2\n\n# load in velocities\nvel_asc = np.fromfile(vel_file_asc, dtype='float32').reshape((length_asc, width_asc))\nvel_desc = np.fromfile(vel_file_desc, dtype='float32').reshape((length_desc, width_desc))\n\n# load in unit vectors\nE_asc = np.fromfile(E_file_asc, dtype='float32').reshape((length_asc, width_asc))\nN_asc = np.fromfile(N_file_asc, dtype='float32').reshape((length_asc, width_asc))\nU_asc = np.fromfile(U_file_asc, dtype='float32').reshape((length_asc, width_asc))\n\nE_desc = np.fromfile(E_file_desc, dtype='float32').reshape((length_desc, width_desc))\nN_desc = np.fromfile(N_file_desc, dtype='float32').reshape((length_desc, width_desc))\nU_desc = np.fromfile(U_file_desc, dtype='float32').reshape((length_desc, width_desc))\n\n# load the frame polygons for plotting\npoly_asc = np.loadtxt(Path('data/' + asc + '.poly'))\npoly_desc = np.loadtxt(Path('data/' + desc + '.poly'))\n\n# load the naf fault trace\nfault_trace = np.loadtxt(Path('data/naf_trace.xy'))\n\nprint('Files loaded.')\nprint('Size of ascending velocity:')\nprint(vel_asc.shape)\nprint('Size of descending velocity:')\nprint(vel_desc.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ec806814","cell_type":"markdown","source":"Next, we'll plot the velocities to make sure they've loaded in correctly. The trace of the NAF will be plotted as a red line.","metadata":{}},{"id":"0a9c12b2","cell_type":"code","source":"# plot input vels\nfig, axs = plt.subplots(1,2,figsize=(15,5))\n\n# plot the ascending velocities, saturating the colour palette from -20 to 20 mm/yr.\nim = axs[0].imshow(vel_asc, extent=[np.amin(lon_asc), np.amax(lon_asc), np.amin(lat_asc), np.amax(lat_asc)], \\\n                   cmap=cm.vik, vmin=-20, vmax=20)\n\n# add the NAF fault trace\naxs[0].plot(fault_trace[:,0], fault_trace[:,1], color=\"red\")\n\n# add the frame polygon\naxs[0].plot(poly_asc[:,0], poly_asc[:,1], color=\"black\", linestyle='dashed')\n\n# display the colorbar, this \"divider\" section is to scale the colorbar size to the plot\ndivider = make_axes_locatable(axs[0])\ncax = divider.append_axes(\"right\", size=\"5%\", pad=\"2%\")\nplt.colorbar(im, cax=cax, label='LOS velocity (mm/yr)')\n\n# set the title\naxs[0].set_title('087A_04904_121313')\n\n# set the x and y limits of the plot\naxs[0].set_xlim(np.amin(lon_asc), np.amax(lon_asc))\naxs[0].set_ylim(np.amin(lat_asc), np.amax(lat_asc))\n\n# label the x and y axes\naxs[0].set_xlabel('Longitude (degrees)')\naxs[0].set_ylabel('Latitude (degrees)')\n\n# repeat for the descending velocities\nim = axs[1].imshow(vel_desc, extent=[np.amin(lon_desc), np.amax(lon_desc), np.amin(lat_desc), np.amax(lat_desc)], \\\n                   cmap=cm.vik, vmin=-20, vmax=20)\naxs[1].plot(fault_trace[:,0], fault_trace[:,1], color=\"red\")\naxs[1].plot(poly_desc[:,0], poly_desc[:,1], color=\"black\", linestyle='dashed')\ndivider = make_axes_locatable(axs[1])\ncax = divider.append_axes(\"right\", size=\"5%\", pad=\"2%\")\nplt.colorbar(im, cax=cax, label='LOS velocity (mm/yr)')\naxs[1].set_title('167D_04884_131212')\naxs[1].set_xlim(np.amin(lon_desc), np.amax(lon_desc))\naxs[1].set_ylim(np.amin(lat_desc), np.amax(lat_desc))\naxs[1].set_xlabel('Longitude (degrees)')\naxs[1].set_ylabel('Latitude (degrees)')\n\n# show the plot\nfig.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ad47611e","cell_type":"markdown","source":"By default, LiCSBAS sets motion towards the satellite as positive, and motion away from the satellite as negative. These velocities are relative to a LiCSBAS-selected reference point within each frame.","metadata":{}},{"id":"b2f9c727-d996-444f-a694-210f8f58aeda","cell_type":"markdown","source":"We can already see a change a the LOS velocites across the fault in both maps. To investigate further, lets take a profile across the fault in the ascending velocities.","metadata":{}},{"id":"3861dbca","cell_type":"markdown","source":"## 3. Decompose the line-of-sight velocities into fault-parallel and vertical\n\nEquation 1 requires fault-parallel velocities, while ours are currently in the satellite LOS.\nWe can estimate fault-parallel velocities by decomposing our LOS velocities into fault-parallel, fault-perpendicular, and vertical velocities.\nThis is done by solving a linear system of equations between our InSAR velocities ($V_{asc}$ and $V_{desc}$) and our component velocities.\nWe convert between the two using the radar incidence angle, $\\theta$, and the azimuth of the along-track satellite heading, $\\alpha$, and the strike of our fault, $\\gamma$. Both $\\theta$ and $\\alpha$ vary pixel-by-pixel.\n\nFirst, let's look at how we would decompose our LOS velocities into East ($V_E$), North ($V_N$), and vertical ($V_U$) velocities:\n\\begin{equation}\n    \\begin{bmatrix} V_{asc} \\\\ V_{desc} \\end{bmatrix} = \\begin{bmatrix} sin(\\theta_{asc})cos(\\alpha_{asc}) & sin(\\theta_{asc})sin(\\alpha_{asc}) & -cos(\\theta_{asc}) \\\\ sin(\\theta_{desc})cos(\\alpha_{desc}) & sin(\\theta_{desc})sin(\\alpha_{desc}) & -cos(\\theta_{desc}) \\end{bmatrix} \\begin{bmatrix} V_E \\\\ V_N \\\\ V_U \\end{bmatrix}\n    \\qquad \\qquad (2)\n\\end{equation}\n\nWe calcualte fault-parallel ($V_{para}$) and fault-perpendicular ($V_{perp}$) velocities as a sum of relavent components of $V_E$ and $V_N$, including an extra term to account for the strike of the fault measured clockwise from North: \n\n\\begin{equation}\n    \\begin{bmatrix} V_{asc} \\\\ V_{desc} \\end{bmatrix} = \\begin{bmatrix} \\begin{pmatrix} sin(\\gamma)sin(\\theta_{asc})cos(\\alpha_{asc})\\\\+ cos(\\gamma)sin(\\theta_{asc})sin(\\alpha_{asc}) \\end{pmatrix} & \\begin{pmatrix} cos(\\gamma)sin(\\theta_{asc})cos(\\alpha_{asc})\\\\+ sin(\\gamma)sin(\\theta_{asc})sin(\\alpha_{asc}) \\end{pmatrix} & -cos(\\theta_{asc}) \\\\ \\begin{pmatrix} sin(\\gamma)sin(\\theta_{desc})cos(\\alpha_{desc})\\\\+ cos(\\gamma)sin(\\theta_{desc})sin(\\alpha_{desc}) \\end{pmatrix} & \\begin{pmatrix} cos(\\gamma)sin(\\theta_{desc})cos(\\alpha_{desc})\\\\+ sin(\\gamma)sin(\\theta_{desc})sin(\\alpha_{desc}) \\end{pmatrix} & -cos(\\theta_{desc}) \\end{bmatrix} \\begin{bmatrix} V_{para} \\\\ V_{perp} \\\\ V_U \\end{bmatrix}\n    \\qquad \\qquad (3)\n\\end{equation}\n\nIn both cases, we have three unknowns and only two data sets, making this an underdetermined system.\nGiven that the amount of data available to us is fixed, we need to reduce the number of component velocities we want to estimate by one so that we can solve for the remaining two.\nWe'll assume that $V_{perp}$ is zero so that we can solve for $V_{para}$ and $V_U$. We choose $V_{perp}$ because we expect the dominant signal to be strike-slip motion on the East-West striking NAF, producing a small North-South component which the Sentinel-1 satellites are particularly insensitive to because of their near-polar orbit.\n\nWe can now rewrite Equation 3:\n\n\\begin{equation}\n    \\begin{bmatrix} V_{asc} \\\\ V_{desc} \\end{bmatrix} = \\begin{bmatrix} sin(\\gamma)sin(\\theta_{asc})cos(\\alpha_{asc})+cos(\\gamma)sin(\\theta_{asc})sin(\\alpha_{asc}) & -cos(\\theta_{asc}) \\\\ sin(\\gamma)sin(\\theta_{desc})cos(\\alpha_{desc})+cos(\\gamma)sin(\\theta_{desc})sin(\\alpha_{desc}) & -cos(\\theta_{desc}) \\end{bmatrix} \\begin{bmatrix} V_{para} \\\\ V_U \\end{bmatrix}\n    \\qquad \\qquad (4)\n\\end{equation}\n\nwhere $V_{asc}$ and $V_{desc}$ are the LOS velocities, $\\theta$ is the radar incidence angle, and $\\alpha$ is the azimuth of the along-track satellite heading. The conversion from LOS to fault-parallel can be simplified to $sin(\\theta)sin(\\alpha + \\gamma)$, however, we only have the unit component vectors available, not the individual values of $\\theta$ and $\\alpha$, so we'll stick with Equation 4.","metadata":{}},{"id":"c5c595c2","cell_type":"markdown","source":"Currently, these velocities are on two slightly different grids. We need to unify the grids so that we can perform the velocity decomposition for shared points.","metadata":{}},{"id":"5e1f499b","cell_type":"code","source":"# limits and intervals for new grid\nlon_min = np.amin([lon_asc[0], lon_desc[0]])\nlon_max = np.amax([lon_asc[-1], lon_desc[-1]])\nlon_int = np.amin([post_lon_asc, post_lon_desc])\nlon_regrid = np.arange(lon_min,lon_max+lon_int,lon_int)\n\nlat_max = np.amax([lat_asc[0], lat_desc[0]])\nlat_min = np.amin([lat_asc[-1], lat_desc[-1]])\nlat_int = np.absolute(np.amin([post_lat_asc, post_lat_desc]))\nlat_regrid = np.arange(lat_min,lat_max+lat_int,lat_int)\n\nxx_regrid, yy_regrid = np.meshgrid(lon_regrid, lat_regrid[::-1])\ncoords_regrid = np.transpose(np.vstack((xx_regrid.flatten(),yy_regrid.flatten())))\n\n# interpolate velocities onto this new grid\nxx_asc, yy_asc = np.meshgrid(lon_asc, lat_asc)\nvel_asc_regrid = interpolate.griddata((xx_asc.ravel(), yy_asc.ravel()), vel_asc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel()))\nvel_asc_regrid = vel_asc_regrid.reshape((len(lat_regrid),len(lon_regrid)))\n\nxx_desc, yy_desc = np.meshgrid(lon_desc, lat_desc)\nvel_desc_regrid = interpolate.griddata((xx_desc.ravel(), yy_desc.ravel()), vel_desc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel()))\nvel_desc_regrid = vel_desc_regrid.reshape((len(lat_regrid),len(lon_regrid)))\n\n# interpolate the component vectors into the new grid\nE_asc_regrid = interpolate.griddata((xx_asc.ravel(), yy_asc.ravel()), E_asc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel())).reshape((len(lat_regrid),len(lon_regrid)))\nN_asc_regrid = interpolate.griddata((xx_asc.ravel(), yy_asc.ravel()), N_asc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel())).reshape((len(lat_regrid),len(lon_regrid)))\nU_asc_regrid = interpolate.griddata((xx_asc.ravel(), yy_asc.ravel()), U_asc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel())).reshape((len(lat_regrid),len(lon_regrid)))\n\nE_desc_regrid = interpolate.griddata((xx_desc.ravel(), yy_desc.ravel()), E_desc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel())).reshape((len(lat_regrid),len(lon_regrid)))\nN_desc_regrid = interpolate.griddata((xx_desc.ravel(), yy_desc.ravel()), N_desc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel())).reshape((len(lat_regrid),len(lon_regrid)))\nU_desc_regrid = interpolate.griddata((xx_desc.ravel(), yy_desc.ravel()), U_desc.ravel(), (xx_regrid.ravel(), yy_regrid.ravel())).reshape((len(lat_regrid),len(lon_regrid)))\n\nprint('Regridding complete.')\nprint('Size of ascending velocity:')\nprint(vel_asc_regrid.shape)\nprint('Size of descending velocity:')\nprint(vel_desc_regrid.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dfe761ec","cell_type":"markdown","source":"Currently the two velocities fields are relative to their own reference pixels. We need to make this reference the same so that the velocities can be decomposed correctly. We'll define a reference window and use the mean of all the velocities within that area as the reference.","metadata":{}},{"id":"1de8c9fc","cell_type":"code","source":"# define new reference pixel\nref_xmin, ref_xmax = 32.65, 32.85\nref_ymin, ref_ymax = 41.1, 41.2\n\n# ref poly for plotting\nref_poly = np.array([[ref_xmin, ref_ymin],\n           [ref_xmin, ref_ymax],\n           [ref_xmax, ref_ymax],\n           [ref_xmax, ref_ymin],\n           [ref_xmin, ref_ymin]])\n\n# get index\nind_xmin = np.argmin(np.absolute(lon_regrid-ref_xmin))\nind_xmax = np.argmin(np.absolute(lon_regrid-ref_xmax))\nind_ymin = np.argmin(np.absolute(lat_regrid-ref_ymin))\nind_ymax = np.argmin(np.absolute(lat_regrid-ref_ymax))\n\n# get ref value\nref_val_asc = np.nanmean(vel_asc_regrid[ind_ymin:ind_ymax+1,ind_xmin:ind_xmax+1])\nref_val_desc = np.nanmean(vel_desc_regrid[ind_ymin:ind_ymax+1,ind_xmin:ind_xmax+1])\n\n# set as new reference\nvel_asc_regrid = vel_asc_regrid - ref_val_asc\nvel_desc_regrid = vel_desc_regrid - ref_val_desc\n\nprint('Referencing complete.')\nprint('Mean value of reference for ascending = ' + str(round(ref_val_asc,3)) + ' mm/yr')\nprint('Mean value of reference for descending = ' + str(round(ref_val_desc,3)) + ' mm/yr')\n\n# plot the los velocity maps with our defined reference window\nlib.plot_maps_with_reference(vel_asc_regrid, lon_regrid, lat_regrid, fault_trace, ref_poly, vel_desc_regrid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"335e6230","cell_type":"markdown","source":"Now we'll run the decomposition for each pixel, assuming no correlation between pixels and a strike of 80&deg;. ","metadata":{}},{"id":"24a74c5f","cell_type":"code","source":"# set strike\nstrike = 80\nstrike_E, strike_N = np.sin(np.deg2rad(strike)), np.cos(np.deg2rad(strike))\n\n# pre-allocate\nvel_para = np.zeros((len(lat_regrid), len(lon_regrid)))\nvel_U = np.zeros((len(lat_regrid), len(lon_regrid)))\n\n# loop through every pixel\nfor ii in np.arange(0,len(lat_regrid)):\n    for jj in np.arange(0,len(lon_regrid)):\n        \n        # create the design matrix\n        G = np.array([[strike_E*E_asc_regrid[ii,jj] + strike_N*N_asc_regrid[ii,jj], U_asc_regrid[ii,jj]], \n                      [strike_E*E_desc_regrid[ii,jj] + strike_N*N_desc_regrid[ii,jj], U_desc_regrid[ii,jj]]])\n        \n        # get the two velocities for this pixel\n        d = np.array([[vel_asc_regrid[ii,jj], vel_desc_regrid[ii,jj]]]).T\n        \n        # solve the linear system for the Up and East velocities\n        m = np.linalg.solve(G, d)\n        \n        # save to arrays\n        vel_para[ii,jj] = m[0, 0]\n        vel_U[ii,jj] = m[1, 0]\n\n# plot decomposed maps\nlib.plot_decomposed_maps(vel_para, vel_U,lon_regrid, lat_regrid, fault_trace, poly_asc, poly_desc)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fac2b682-687d-446d-aa97-1ef09dad0515","cell_type":"markdown","source":"Note how we only get the decomposed velocities in the overlap area, where we have both line-of-sights to work with.","metadata":{}},{"id":"c117166b","cell_type":"markdown","source":"## 4. Profile the fault-parallel velocities","metadata":{}},{"id":"5d61b041","cell_type":"markdown","source":"We'll now profile our decomposed fault-parallel velocities to produce a dataset which we can then apply our screw dislocation model to. First, we need to project our lat-long coordinates into Universal Transverse Mercator (UTM) so that the profile distances are in metres and not degrees. After this projection, our velocities will no longer be on a regular grid, so we'll plot them using scatter instead of imshow.","metadata":{}},{"id":"0847dfa3","cell_type":"code","source":"# Convert to UTM using gdal\n\n# get the utm zone projection\nutm_crs_list = pyproj.database.query_utm_crs_info(\n    datum_name=\"WGS 84\",\n    area_of_interest = pyproj.aoi.AreaOfInterest(\n        west_lon_degree  = np.amin(lon_regrid),\n        south_lat_degree = np.amin(lat_regrid),\n        east_lon_degree  = np.amax(lon_regrid),\n        north_lat_degree = np.amax(lat_regrid),\n    ),\n)\nutm_crs = pyproj.CRS.from_epsg(utm_crs_list[0].code)\n\n# create transformer for LL to UTM\ntransformer = pyproj.Transformer.from_crs('epsg:4326', utm_crs)\n\n# apply transform to our grids of lat long coordinates\nxx_utm, yy_utm = transformer.transform(yy_regrid, xx_regrid)\n\n# apply transform to fault trace\nfault_trace_utm = fault_trace.copy()\nfault_trace_utm[:,0], fault_trace_utm[:,1] = transformer.transform(fault_trace[:,1], fault_trace[:,0])\n\n# convert utm metres to km (easier to work with for plotting)\nxx_utm = xx_utm / 1000\nyy_utm = yy_utm / 1000\nfault_trace_utm = fault_trace_utm / 1000\n\n# get new limits for plotting\nval_ind_row, val_ind_col = np.where(~np.isnan(vel_U).all(axis=0))[0], np.where(~np.isnan(vel_U).all(axis=1))[0]\nxlim = [xx_utm[-1,val_ind_row[0]], xx_utm[-1,val_ind_row[-1]]]\nylim = [yy_utm[val_ind_col[-1],0], yy_utm[val_ind_col[0],0]]\n\n# plot the utm velocity maps\nlib.plot_utm_maps(xx_utm, yy_utm, vel_para, vel_U, fault_trace_utm, xlim, ylim)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dde38284","cell_type":"code","source":"# Set the profile parameters\n\n# rough middle profile\n#####################################\nprof_start = (573, 4450)\nprof_end = (540, 4595)\nprof_params = {\n    \"nbins\": 100, # number of bins to split the profile into\n    \"width\": 5  # total width of the profile in km\n}\n#####################################\n\n# run the profiler, the outputs are as follows:\n# - bin_val = mean value of each bin\n# - prof_bin_mids = distance along the profile to the middle of each bin\n# - points_val = every velocity within the profile\n# - points_dist = distance along the profile to every point within the profile\n# - points_poly = polygon that defines the profile\nbin_val, prof_bin_mids, points_val, points_dist, points_poly \\\n    = lib.profile_data(xx_utm,yy_utm,vel_para,prof_start,prof_end,prof_params)\n\n# calculate profile-fault intersection angle\nintersect_dist, intersect_angle = lib.profile_fault_intersection(prof_start,prof_end,fault_trace_utm)\n\n# plot the profile in map view and in cross-section\nlib.plot_profile(xx_utm, yy_utm, vel_para, fault_trace_utm, prof_start, prof_end, points_poly, xlim, ylim, \n                 points_dist, points_val, prof_bin_mids, bin_val, intersect_dist, intersect_angle) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2c00b120","cell_type":"markdown","source":"I've included the intersection angle between the fault and the profile line on the right-hand plot.\nWe want this angle to be 90&deg;, otherwise the signal will become smeared and effect our results.\n\nThe pink dot marks the start of the profile, and the black dot marks the end. The three red lines between these show the main profile line and the extent of the profile width.\n\nOur profiled velocities are shown on the right. These are projected onto the profile line, and so are given at distance along the profile from prof_start, which is located at 0 distance. The units of distance are the same as those for the profiled data set. The vertical dashed line marks where the profile line intersects the fault trace of the NAF.\n\nWhile the profiled velocities are a little noisy, you should be able to see an overall change in velocity across the fault with a shape that resembles an arctangent function.","metadata":{}},{"id":"736ca519","cell_type":"markdown","source":"## 5. Forward model\n\nNow that we have our data, let's produce a simple forward model to get an idea of what model parameters produce a reasonable fit.","metadata":{}},{"id":"44ab5845","cell_type":"code","source":"# Slip, locking depth, and offset\n#####################################\ns = 20 # mm/yr\nd = 15 # km\nc = -5 # mm/yr\n#####################################\n\n# shift profile so that the fault is at 0 km\nx_prof = points_dist - intersect_dist\n\n# Vector of positions every 1 km for -100 km to 100 km\nx = np.arange(-100,101,1)\n\n# run the forward model\nv = lib.screw_disc(x*1000, s/1000, d*1000, c/1000)\n\n# calculate rms misfit by running the forward model for x positions with velocities\nv_forward = lib.screw_disc(x_prof*1000, s/1000, d*1000, c/1000)\nrms_forward = lib.rms_misfit(points_val,v_forward*1000)\n\n# Plot comparison\nlib.plot_profile_model(x_prof, points_val, x, v, s, d, c, rms_forward)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c657be77","cell_type":"markdown","source":"To see how well you can all model the fault, lets model the same profile and then share the results.\n\nSet your profile to the following:\n```\nprof_start = (573, 4450)\nprof_end = (540, 4595)\n```\n\nOnce you have your best model, please share your best-fit parameters in this form:\n\nhttps://forms.gle/5Ubp6MXoafrdYDVC6","metadata":{}},{"id":"2ec0c5c8","cell_type":"markdown","source":"## 6. Fault creep\n\nSo far we've assumed that the NAF is locked from the surface down to a given depth, below which the fault is slipping aseismically. This gives a fault-parallel velocity of zero at the fault trace. Depending on where you have drawn your profile lines so far, you may have noticed a step in the velocities across the fault that is larger than the noise level. This may be fault creep, where the fault is also slipping aseismically at a shallow depth up to the surface. This fault creep occurs alongside the deeper interseismic slip.\n\nA schematic diagram of fault creep is shown in Figure 5.\n\n<img src=\"figures/faultCreep.png\" style=\"float: centre;\" width=\"500\"/>\n\n*Figure 5: (a) Schematic diagram of our fault creep model. (b) Forward model showing how the fault creep is expected to change our observed signal. From Hussian et al. (2016).*\n\nWe can model a combination of interseismic strain accumulation and fault creep to calculate a fault parallel velocity, $v$, at fault-perpendicular distance, $x$, using Equation 4:\n\n\\begin{equation}\nv(x) = -\\frac{s}{\\pi}arctan\\left(\\frac{x+x_c}{d_1}\\right) + C\\left[\\frac{1}{\\pi}arctan\\left(\\frac{x+x_c}{d_2}\\right) - H(x+x_c)\\right] + c \\qquad \\qquad (4)\n\\end{equation}\n\nWe retain the screw dislocation model from before, where slip, $s$ occurs below a depth, $d_1$. For the shallow creep, occuring at a rate of $C$ between the surface and depth $d_2$, we use a back slip approach. This models the creep as the sum of slip on the entire fault plane using a Heaviside function ($H$) plus a screw dislocation in the opposite sense to the plate motion at depth $d_2$. We also retain the static offset, $c$, and include a new offset to the fault location, $x_c$. Sometimes the observed signal may not exactly align with the mapped fault trace, and so it can be useful to include a small offset to the location of the fault.\n\nLet's take a new profile across a creeping part of the NAF.","metadata":{}},{"id":"c285e2c3","cell_type":"code","source":"# creep\nprof_start = (508, 4450)\nprof_end = (480, 4620)\n\nprof_params = {\n    \"nbins\": 100, # number of bins to split the profile into\n    \"width\": 5  # total width of the profile in km\n}\n\n# run the profiler\nbin_val, prof_bin_mids, points_val, points_dist, points_poly \\\n    = lib.profile_data(xx_utm,yy_utm,vel_para,prof_start,prof_end,prof_params)\n\n# calculate profile-fault intersection angle\nintersect_dist, intersect_angle = lib.profile_fault_intersection(prof_start,prof_end,fault_trace_utm)\n\n# plot the profile in map view and in cross-section\nlib.plot_profile(xx_utm, yy_utm, vel_para, fault_trace_utm, prof_start, prof_end, points_poly, xlim, ylim, \n                 points_dist, points_val, prof_bin_mids, bin_val, intersect_dist, intersect_angle) \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0889e783","cell_type":"markdown","source":"Next, we'll run a forward model.","metadata":{}},{"id":"00ea4ecf","cell_type":"code","source":"# Slip and locking depth\n#####################################\ns1 = 23 # mm/yr\ns2 = 9 # mm/yr\nd1 = 18 # km\nd2 = 7 # km\nc = -8 # mm/yr\nxc = 0 # km\n#####################################\n\n# shift profile so thast fault is at 0 km\nx_prof = points_dist - intersect_dist\n\n# Vector of positions -80 km to 80 km, sampling at every 100 m to better capture the creep motion near fault\nx = np.arange(-80,81,0.1)\n\n# run the forward model\nv = lib.fault_creep(x*1000, s1/1000, s2/1000, d1*1000, d2*1000, c/1000, xc=xc*1000)\n\n# calculate rms misfit by running the forward model for x positions with velocities\nv_forward = lib.fault_creep(x_prof*1000, s1/1000, s2/1000, d1*1000, d2*1000, c/1000, xc=xc*1000)\nrms_forward = lib.rms_misfit(points_val,v_forward*1000)\n\n# plot profile with your model\nlib.plot_creep_profile(x_prof, points_val, x, v, s1, s2, d1, d2, c, rms_forward)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7e8e95fa-4f92-4fc3-bfde-331aa91c1c9e","cell_type":"markdown","source":"What's your best answer? \n\nLet us know by filling out this form:\n\nhttps://forms.gle/a4oVvdpVh8RQreGe9","metadata":{}},{"id":"8128597f","cell_type":"markdown","source":"## 7. Estimating shear strain rate from 1-D velocity profiles\n\nEstimates of strain rate can highligh areas of concentrated deformation, an important product for understanding both seismic hazard the wider-scale kinematics. The state of strain in the lithosphere can be described using a strain rate tensor, $\\dot{\\varepsilon}$:\n\n\\begin{equation}\n    \\dot{\\varepsilon} = \\begin{bmatrix}\n    \\frac{\\partial V_E}{\\partial x} & \\frac{1}{2}\\left(\\frac{\\partial V_E}{\\partial y}+\\frac{\\partial V_N}{\\partial x}\\right) & \\frac{1}{2}\\left(\\frac{\\partial V_E}{\\partial z}+\\frac{\\partial V_U}{\\partial x}\\right) \\\\    \n    \\frac{1}{2}\\left(\\frac{\\partial V_N}{\\partial x}+\\frac{\\partial V_E}{\\partial y}\\right) & \\frac{\\partial V_N}{\\partial y} & \\frac{1}{2}\\left(\\frac{\\partial V_N}{\\partial z}+\\frac{\\partial V_U}{\\partial y}\\right) \\\\    \n    \\frac{1}{2}\\left(\\frac{\\partial V_U}{\\partial x}+\\frac{\\partial V_E}{\\partial z}\\right) & \\frac{1}{2}\\left(\\frac{\\partial V_U}{\\partial y}+\\frac{\\partial V_N}{\\partial z}\\right) & \\frac{\\partial V_U}{\\partial z}    \n    \\end{bmatrix} \\qquad \\qquad (5)\n\\end{equation}\n\nwhere $v_E$, $v_N$, and $v_U$ are the velocities in the Cartesian coordinate direction, $x$, $y$, and $z$.\n\nIn this instance, we have fault-parellel velocities at distances perpendicular to the fault, and so we can only estimate the shear strain across the fault. For our screw dislocation model, we can forward model the shear strain, $e_{shear}$, using (Savage & Burford, 1973):\n\n\\begin{equation}\ne_{shear} = \\left(\\frac{sd}{2\\pi}\\right)\\left(x^2+d^2\\right)^{-1} \\qquad \\qquad (6)\n\\end{equation}\n\nLet's start by calculating the shear rate for the screw dislocation model that we fit to our original profile, using both a forward model (Equation 6) and by calculating the gradient in the modelled velocities.","metadata":{}},{"id":"9f38501c","cell_type":"code","source":"# Slip rate and locking depth\n#####################################\ns = 19 # mm/yr\nd = 11 # km\nc = -5.7 # mm/yr\n#####################################\n\n# Original profile line\nprof_start = (573, 4450)\nprof_end = (540, 4595)\n\nprof_params = {\n    \"nbins\": 100, # number of bins to split the profile into\n    \"width\": 5  # total width of the profile in km\n}\n\n# run the profiler\nbin_val, prof_bin_mids, points_val, points_dist, points_poly \\\n    = lib.profile_data(xx_utm,yy_utm,vel_para,prof_start,prof_end,prof_params)\n\n# calculate profile-fault intersection angle\nintersect_dist, intersect_angle = lib.profile_fault_intersection(prof_start,prof_end,fault_trace_utm)\n\n# shift profile so that the fault is at 0 km\nx_prof = points_dist - intersect_dist\n\n# Vector of positions every 1 km for -100 km to 100 km\nx = np.arange(-100,101,1)\n\n# run the forward model\nv = lib.screw_disc(x*1000, s/1000, d*1000, c/1000)\n\n# calculate shear strain rate using Equation 6\ne_shear = lib.shear_strain(x*1000, s/1000, d*1000)\n\n# also calculate shear strain rate based purely on velocity gradient\ne_shear_grad = np.gradient(v,x*1000)\n\n# plot the velocity and strain profile\nlib.plot_strain_profile(x_prof, points_val, x, v, intersect_angle, e_shear, e_shear_grad)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"87d7474d","cell_type":"markdown","source":"The factor of two difference between the modelled strain rate and estimated strain rate reflects a difference between engineering shear strain and tensor strain rate. For further information, have a look in the Supporting Information of Weiss et al. (2020).\n\nWe can get nice smooth estimates of strain rate from our screw dislocation models. In real studies, we often want to estimate strain rates directly from our velocities, as this will capture signals that are not represented in our model. However, we still require some degree of smoothing to suppress short-wavelength noise in the InSAR. This noise, while small compared to the tectonic signal, can cause large gradients between adjacent points that then drown out the underying tectonic strain rate.\n\nLet's plot both the strain rate directly calculated from the binned profiled fault-parallel velocities, and one calculated from the same velocities but smoothed with a sliding window average. Try changing the size of the smoothing window.","metadata":{}},{"id":"a3e26df2","cell_type":"code","source":"# Window size for smoothing, must be an odd number\n#####################################\nwind_size = 9\n#####################################\n\n# shift fault location to 0 km\nx_prof = prof_bin_mids - intersect_dist\n\n# calcualte gradient of original binned velocities\ne_shear = np.gradient(bin_val/1000, x_prof*1000)\n\n# apply a sliding mean window to smooth out some of the noise\nx_smoothed, vel_smoothed = lib.sliding_window_mean(x_prof, bin_val, wind_size)\n\n# calculated the gradient from the smoothed velocities\ne_shear_smoothed = np.gradient(vel_smoothed/1000, x_smoothed*1000)\n\n# Plot comparison\nfig, axs = plt.subplots(1,1,figsize=(15,8))\n\nplt.plot(x_prof, e_shear, c='r', label='Original binned velocities')\nplt.plot(x_smoothed, e_shear_smoothed, c='b', label='Smoothed velocities')\nplt.plot([0, 0],[axs.get_ylim()[0], axs.get_ylim()[1]], color='grey', linestyle='dashed')\nplt.xlabel('Distance from fault (km)')\nplt.ylabel('Shear strain rate (/yr)')\nplt.legend(fontsize=\"x-large\")\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"79254634","cell_type":"markdown","source":"If we calculate the strain rate directly from the binned velocities (which have themselves already been smoothed to some degree), then the strain signal we would expect to see based on Equation 5 is completely masked.\n\nBy applying a smoothing window (a window size of 9 works quite well), we can bring out the higher strain across the fault trace. If the window size is increased too far, then we can actually smooth out the original interseismic signal, and this peak disappears again. How we filter out high-frequency noise in the velocities is integral to our estimates of strain rate.\n\nFor further reading, I recommend Weiss et al. (2020), who apply the Velmap method to all of Turkey, and Ou et al. (2022), who use a median filter method to localise strain onto a number of faults in the Tibetan Plateau.","metadata":{}},{"id":"8abe775f","cell_type":"markdown","source":"## 8. Estimating strain rates from 2-D surface velocities.\n\nIn addition to estimating strain rates from profiled velocities, we can also calculate strain rate in 2-D from our decomposed fault-parallel velocities. Based on our previous assumption of zero fault-perpendicular motion, we can split the fault-parallel velocities into North and East components, allowing us to calculate the gradients of both in $x$ and $y$.\n\nThis method is based on the work of: <br>\n*Ou, Q., Daout, S., Weiss, J. R., Shen, L., Lazecký, M., Wright, T. J., & Parsons, B. E. (2022). Large‐Scale Interseismic Strain Mapping of the NE Tibetan Plateau From Sentinel‐1 Interferometry. Journal of Geophysical Research: Solid Earth, 127(6), e2022JB024176.*\n\nAs with the profiled velocities, we'll first need to filter the decomposed fault-parallel velocities to remove any short-wavelength noise. Try experimenting with the output pixel size.","metadata":{}},{"id":"2ba83503","cell_type":"code","source":"# Set pixel size to downsample too (in km)\n#####################################\npixel_size = 10\n#####################################\n\n# Define working region\nregion=\"32/35/40/42\"\n\n# use pygmt's block median filter to mitigate short-wavelength signals\nvel_para_median = pygmt.blockmedian(\n    x=xx_regrid.flatten(), y=yy_regrid.flatten(), z=vel_para.flatten(), region=region, spacing=str(pixel_size)+\"k\")\n\n# convert from an ascii three-column list of xyz, to a binary grid\nvel_para_median_grd = pygmt.xyz2grd(data=vel_para_median, region=region, spacing=str(pixel_size)+\"k\")\n\n# get extents from grid info\nlon_min = vel_para_median_grd.coords['lon'].values[0]\nlon_max = vel_para_median_grd.coords['lon'].values[-1]\nlat_min = vel_para_median_grd.coords['lat'].values[0]\nlat_max = vel_para_median_grd.coords['lat'].values[-1]\nxlim = (lon_min, lon_max)\nylim = (lat_min, lat_max)\n\n# convert to numpy and flip array upside down to match default origin\nvel_para_median_array = np.flipud(vel_para_median_grd.to_numpy())\n\n# plot the filtered velocities\nfig, ax = plt.subplots(figsize=(10,10))\nim = ax.imshow(vel_para_median_array, interpolation='none', cmap=cm.vik, \n               vmin=-20, vmax=20, extent=(lon_min,lon_max, lat_min, lat_max))\nax.plot(fault_trace[:,0], fault_trace[:,1], color=\"red\")\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=\"2%\")\nplt.colorbar(im, cax=cax, label='Fault-parallel velocity (mm/yr)')\nax.set_aspect('equal', 'box')\nax.set_title('Filtered fault-parallel velocities')\nax.set_xlabel('Longitude')\nax.set_ylabel('Latitude')\nax.set_xlim(xlim)\nax.set_ylim(ylim)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6048000b","cell_type":"code","source":"# calculate Ve and Vn from block_median fault-parallel velocities\nvel_east = strike_E * vel_para_median_array\nvel_north = strike_N * vel_para_median_array\n\n# plot velocity components\nfig, axs = plt.subplots(1,2, figsize=(17,5), sharey='all')\n\n# East velocity\nim = axs[0].imshow(vel_east, interpolation='none',cmap=cm.vik, \n                   vmin=-20, vmax=20, extent=(lon_min,lon_max, lat_min, lat_max))\naxs[0].plot(fault_trace[:,0], fault_trace[:,1], color=\"red\")\ndivider = make_axes_locatable(axs[0])\ncax = divider.append_axes(\"right\", size=\"2%\", pad=\"2%\")\nplt.colorbar(im, cax=cax, label='Ve (mm/yr)')\naxs[0].set_aspect('equal', 'box')\naxs[0].set_title('East velocity')\naxs[0].set_xlabel('Longitude')\naxs[0].set_ylabel('Latitude')\naxs[0].set_xlim(xlim)\naxs[0].set_ylim(ylim)\n\n# North velicity\nim = axs[1].imshow(vel_north, interpolation='none',cmap=cm.vik, \n                   vmin=-20, vmax=20, extent=(lon_min,lon_max, lat_min, lat_max))\naxs[1].plot(fault_trace[:,0], fault_trace[:,1], color=\"red\")\ndivider = make_axes_locatable(axs[1])\ncax = divider.append_axes(\"right\", size=\"2%\", pad=\"2%\")\nplt.colorbar(im, cax=cax, label='Vn (mm/yr)')\naxs[1].set_aspect('equal', 'box')\naxs[1].set_title('North velocity')\naxs[1].set_xlabel('Longitude')\naxs[1].set_xlim(xlim)\naxs[1].set_ylim(ylim)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"30ccfdbe","cell_type":"code","source":"# calculate velocity gradients\ndVedy = (vel_east[1:]-vel_east[:-1]) / pixel_size / 10**6  # mm/yr velocity difference divided by pixel spacing in km\ndVedx = (vel_east[:,1:]-vel_east[:,:-1]) / pixel_size / 10**6  \ndVndy = (vel_north[1:]-vel_north[:-1]) / pixel_size / 10**6  # mm/yr velocity difference divided by pixel spacing in km\ndVndx = (vel_north[:,1:]-vel_north[:,:-1]) / pixel_size / 10**6  \n\n# # calculate shape of final strain rate field, 1 pixel smaller than velocity grid because of gradients\nstrain_shape0 = vel_east.shape[0]-1\nstrain_shape1 = vel_east.shape[1]-1\n\n# calculate elements of a 2x2 horizontal strain tensor \nexx = dVedx[:strain_shape0, :strain_shape1]\neyy = dVndy[:strain_shape0, :strain_shape1]\nexy = (dVedy[:strain_shape0, :strain_shape1]+dVndx[:strain_shape0, :strain_shape1])/2\n\n# calculate maximum shear \nshear = np.sqrt(exy**2 + ((exx-eyy)**2)/4) # in units of strain\nshear = shear * 10**9 # in units of nanostrain\n\n# plot maximum shear\nfig, ax = plt.subplots(figsize=(10,10))\nim = ax.imshow(shear, interpolation='none',cmap=cm.lajolla, vmin=0, vmax=500, extent=(lon_min,lon_max, lat_min, lat_max))\nax.plot(fault_trace[:,0], fault_trace[:,1], color=\"red\")\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=\"2%\")\nplt.colorbar(im, cax=cax, label='Shear (nst/yr)')\nax.set_aspect('equal', 'box')\nax.set_title('Maximum Shear')\nax.set_xlabel('x-coord (km)')\nax.set_ylabel('y-coord (km)')\nax.set_xlim(xlim)\nax.set_ylim(ylim)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"737d483a","cell_type":"markdown","source":"## 9. Extension - Bayesian inversion for profile modelling\n\nBayesian inversions are one way we can estimate model parameters and their uncertainties in geophysics. We take some prior knowledge about the model (e.g. limits of the model parameter values) and combine this with a likelihood function based on the observations to estimate the posterior probability (i.e. the likelihood of our model parameters being the true values given the data). By exploring a range of model parameter values, we can build up a a posterior probability distribution which tells us both our \"best fit\" values, known as the \"maximum a posteriori probability (MAP)\" solution, and allows us to estimate the uncertainties on this solution.\n\nWe'll assume uniform priors for each model parameter, meaning all values between the upper and lower limits are equally likely. Values outside of these limits are \"impossible\" and will be rejected in our inversion.\n\nWe use the following limits for our uniform priors:\n- $0 \\leq s \\leq 40$ mm/yr\n- $1 \\leq d \\leq 50$ km\n- $-10 \\leq c \\leq 10$ mm/yr\n\nAssuming our errors are Gaussian, we can find the maximum likelihood by minimising the weighted difference between the observed velocities, $\\mathbf d$, and the model velocities, $g(\\mathbf{m})$:\n\\begin{equation}\n    \\sum (\\mathbf d-g(\\mathbf{m}))*W*(\\mathbf d-g(\\mathbf{m}))\n\\end{equation}\nwhere $W$ contains the weight for every velocity. Weighting the data is useful when some velocities have larger errors than others. For simplicity, we'll assume a uniform uncertainty of 1 mm/yr (1 standard deviation) across all of our velocities.\n\nIn order to explore the posterior distribution (i.e. test a large number of model parameter values) we'll use a Markov Chain Monte Carlo (MCMC) method.\nOur MCMC performs the following steps:\n- Take a starting model and add a random step to each parameters.\n- Test whether this new model is within the prior limits, rejecting the model if not.\n- Calculate the likelihoods for both models.\n- If the new model has a higher likelihood, then accept this model. Also accept a number of models that are worse to help the Monte Carlo explore the full parameter space.\n\nWe need to allow the MCMC to sometimes accept less likely models to avoid local minima. These are models that are good compared to the surrounding models (in the parameter space), but are not the true best model (called the global minima).","metadata":{}},{"id":"70e0c46d","cell_type":"code","source":"importlib.reload(lib)\nnp.random.seed(1)\n\n# inversion setup\n#####################################\nn_iterations = 10000 # don't go above this value of 10,000 in the practical\n#####################################\n\n# take profiled velocities and shift the fault to be at zero\nx_prof = points_dist - intersect_dist\nv_prof = points_val\n\n# model params and their limits\nm_start = np.array([5, 5, 0], dtype=np.double) # slip in mm/yr, locking depth in km\nm_min = np.array([0, 1, -10], dtype=np.double)\nm_max = np.array([40, 50, 10], dtype=np.double)\n\n# variance-covariance matrix, currently 1 mm/yr uncertainties\nvcm = np.eye(len(x_prof))\n\n# convert all units to metres\nx = x_prof * 1000\nv = v_prof / 1000\nm_start = m_start * np.array([0.001, 1000, 0.001])\nm_min = m_min * np.array([0.001, 1000, 0.001])\nm_max = m_max * np.array([0.001, 1000, 0.001])\nvcm = vcm / 1e6\n\n# inversion setup\nburn_in = round(n_iterations/100)\nacceptance_coef = 0.001\n\n# weightings\nW = np.linalg.inv(vcm)\n\n# pre-allocate arrays\nmodels_saved=np.zeros((n_iterations,len(m_start))) * np.nan\nll_saved=np.zeros((n_iterations,1)) * np.nan\nn_accept = 0 # number of accepted models\nn_reject = 0 # number of rejected models\n\n# pass starting model to current model\nm_current = m_start.copy()\n\n# run inversion\nfor ii in range(n_iterations):\n    \n    # propose model using different step sizes for each parameter\n    m_trial = m_current.copy()\n    m_trial[0] = m_trial[0] + np.random.normal(loc=0, scale=2.5, size=1)/1000 # slip rate\n    m_trial[1] = m_trial[1] + np.random.normal(loc=0, scale=2.5, size=1)*1000 # locking depth\n    m_trial[2] = m_trial[2] + np.random.normal(loc=0, scale=1, size=1)/1000 # offset\n    \n    # check limits and skip the rest of the loop if any parameter is invalid\n    if not(lib.prior(m_trial,m_min,m_max)):\n        n_reject += 1\n        models_saved[ii,:] = m_current\n        continue\n    \n    # calculate likelihood for the current and trial models\n    ll_current = lib.likelihood(x, v, m_current, W)\n    ll_trial = lib.likelihood(x, v, m_trial, W)\n    \n    # test whether to keep trial model\n    #if np.exp(acceptance_coef*(ll_trial-ll_current)) > np.random.uniform(low=0, high=1,size=1):\n    if np.exp(acceptance_coef*(ll_current-ll_trial)) > np.random.uniform(low=0, high=1,size=1):\n        m_current = m_trial\n        ll_current = ll_trial\n        n_accept += 1\n    else:\n        n_reject += 1\n    models_saved[ii,:] = m_current\n    ll_saved[ii] = ll_current\n    \n# convert back from metres to mm/yr and km\nmodels_saved[:,0] = models_saved[:,0] * 1000 # slip rate\nmodels_saved[:,1] = models_saved[:,1] / 1000 # locking depth\nmodels_saved[:,2] = models_saved[:,2] * 1000 # offset\n\n# find best fit model using min of likelihood function\nbest_model = models_saved[np.nanargmin(ll_saved),:]\n\nprint('Inversion complete')\nprint('Number of accepted models = ' + str(n_accept))\nprint('Number of rejected models = ' + str(n_reject))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0dc6960e","cell_type":"markdown","source":"First, we'll plot the accepted trial models for the slip rate and locking depth to see how the algorithm explores the parameter space.\nWe'll show the first 1% of iterations in red and the rest in blue.\nThese early iterations are often termed a \"burn-in\" period, where the inversion is moving from the start position towards the (global) minimum, which it then begins to explore.","metadata":{}},{"id":"f578b5c6","cell_type":"code","source":"# plot walker \nplt.figure()\nplt.plot(models_saved[:burn_in,0], models_saved[:burn_in,1], color='red', alpha=0.3)\nplt.plot(models_saved[burn_in:,0], models_saved[burn_in:,1], color='blue', alpha=0.3)\nplt.xlabel('Slip rate (mm/yr)')\nplt.ylabel('Locking depth (km)')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"972309d5","cell_type":"markdown","source":"We can also look at how the inversion explored the parameter space by plotting the likelihood function value for each iteration. The lowest likelihood will be located within a minima, while the higher likelihoods throughout show the inversion accepting worse models to help it escape local minima.","metadata":{}},{"id":"460a5fee","cell_type":"code","source":"# plot likelihood value throughout monte carlo\nfig, axs = plt.subplots(1,1,figsize=(15,8))\n\naxs.scatter(np.arange(1,len(ll_saved)+1),ll_saved, s=3)\naxs.set_xlabel('Number of iterations')\naxs.set_ylabel('Weighted residual')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1d67d42a","cell_type":"markdown","source":"Next, lets plot our best model on top of the profiled velocities.","metadata":{}},{"id":"a4516ec4","cell_type":"code","source":"# calculate rms misfit\nv_final = lib.screw_disc(x_prof, best_model[0], best_model[1], best_model[2])\nbest_rms = lib.rms_misfit(v_prof,v_final)\n\n# for plotting\nx = np.arange(-100,101,1)\nv_final_plot = lib.screw_disc(x, best_model[0], best_model[1], best_model[2])\n\nlib.plot_profile_model(x_prof, v_prof, x, v_final_plot/1000, round(best_model[0],2), round(best_model[1],2), round(best_model[2],2), best_rms)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"efa4077f","cell_type":"markdown","source":"Now we'll plot histograms for each model parameter. The overall shape of these histograms should be gaussian, although they may be skewed to one side. They may also be quite rough depending on the number of iterations that have been run. By fitting a gaussian to each histogram, we can estimate the standard deviation of each, which is a measure of the uncertainty on our estimates.\n\nWe'll plot the best model values as vertical red lines. These should roughly line up with the peaks of our histograms.","metadata":{}},{"id":"0446aa5e","cell_type":"code","source":"# calculate mean and standard deviation for each parameter\ngauss_s = stats.norm.fit(models_saved[burn_in:,0])\ngauss_d = stats.norm.fit(models_saved[burn_in:,1])\ngauss_c = stats.norm.fit(models_saved[burn_in:,2])\n\n# create figure\nfig, axs = plt.subplots(1, 3, figsize=(15,8))\n\n# plot histograms\n_, bins_s, _ = axs[0].hist(models_saved[burn_in:,0], bins=20, density=True)\n_, bins_d, _ = axs[1].hist(models_saved[burn_in:,1], bins=20, density=True)\n_, bins_c, _ = axs[2].hist(models_saved[burn_in:,2], bins=20, density=True)\n\n# create gaussian fit lines\ngauss_fit_s = stats.norm.pdf(bins_s, gauss_s[0], gauss_s[1])\ngauss_fit_d = stats.norm.pdf(bins_d, gauss_d[0], gauss_d[1])\ngauss_fit_c = stats.norm.pdf(bins_c, gauss_c[0], gauss_c[1])\n\n# plot gaussian fits\naxs[0].plot(bins_s, gauss_fit_s)\naxs[1].plot(bins_d, gauss_fit_d)\naxs[2].plot(bins_c, gauss_fit_c)\n\n# label mean and sd\naxs[0].text(0.02, 0.97, 'mean = ' + str(round(gauss_s[0],2)), fontsize=14, transform = axs[0].transAxes)\naxs[0].text(0.02, 0.94, 'sd = ' + str(round(gauss_s[1],2)), fontsize=14, transform = axs[0].transAxes)\naxs[1].text(0.02, 0.97, 'mean = ' + str(round(gauss_d[0],2)), fontsize=14, transform = axs[1].transAxes)\naxs[1].text(0.02, 0.94, 'sd = ' + str(round(gauss_d[1],2)), fontsize=14, transform = axs[1].transAxes)\naxs[2].text(0.02, 0.97, 'mean = ' + str(round(gauss_c[0],2)), fontsize=14, transform = axs[2].transAxes)\naxs[2].text(0.02, 0.94, 'sd = ' + str(round(gauss_c[1],2)), fontsize=14, transform = axs[2].transAxes)\n\n# plot best model values\naxs[0].plot([best_model[0], best_model[0]],[0, axs[0].get_ylim()[1]], color=\"red\")\naxs[1].plot([best_model[1], best_model[1]],[0, axs[1].get_ylim()[1]], color=\"red\")\naxs[2].plot([best_model[2], best_model[2]],[0, axs[2].get_ylim()[1]], color=\"red\")\n\naxs[0].set_title('Slip rate', fontsize=16)\naxs[1].set_title('Locking depth', fontsize=16)\naxs[2].set_title('Offset', fontsize=16)\n\naxs[0].set_xlabel('Slip rate (mm/yr)', fontsize=14)\naxs[1].set_xlabel('Locking depth (km)', fontsize=14)\naxs[2].set_xlabel('Offset (mm/yr)', fontsize=14)\n\nfig.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5731bea6","cell_type":"markdown","source":"As we saw in the \"walker\" plot, there is a trade off between slip rate and locking depth, with an increase in one producing an increase in the other.\n\nLets replot the histograms above while also show the distribution of each model parameter against the other. This should make correlations between model parameters clearer to see. We'll use the Seaborn package for this, as it has a pre-made function for generate these multivariate plots. Its well worth an investigate if you want to use python to plot more scientific data in future.","metadata":{}},{"id":"9693cdcc","cell_type":"code","source":"# This plot can take a couple minutes to run (dependent on the number of iterations)\n\n# multivariate plot\nmodels_df = pd.DataFrame(data=models_saved, columns=[\"Slip rate (mm/yr)\", \"Locking depth (km)\", \"Offset (mm/yr)\"])\ng = sns.PairGrid(models_df, corner=True)\ng.map_diag(sns.histplot)\ng.map_lower(sns.kdeplot) # use this to plot as contours instead (runs slower)\ng.fig.set_size_inches(13,13)\n\n# add red dots for our best model\ng.axes[1,0].scatter(best_model[0], best_model[1], c='red')\ng.axes[2,0].scatter(best_model[0], best_model[2], c='red')\ng.axes[2,1].scatter(best_model[1], best_model[2], c='red')\n\nplt.show()","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"id":"1e256bcc","cell_type":"code","source":"# compare just slip rate and locking depth\nmodels_df = pd.DataFrame(data=models_saved[:,0:2], columns=[\"Slip rate (mm/yr)\", \"Locking depth (km)\"])\nax = sns.jointplot(data=models_df, x=\"Slip rate (mm/yr)\", y=\"Locking depth (km)\", kind=\"hex\", height=8)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1056dd3d","cell_type":"markdown","source":"## Conclusion\n\nHopefully, you now have a basic understanding of how we measure and model interseismic deformation. This practical has been shared under an open-access licence (see repo), so feel free to pass it on and utilise any of the underlying code. \n\nIf you are interested in performing velocity decompositions on a larger scale, have a look at our open-access Matlab package:\nhttps://github.com/andwatson/decompose_insar_velocities.\n\nIf you would like to reference InSAR LOS velocities to 3D GNSS using method in Ou et al., (2022), check out the Python code deposited on Zenodo: \nhttps://zenodo.org/record/6546922.\n\nAn alternative way to reference InSAR LOS velocities to 3D GNSS using VELMAP (Wang & Wright, 2012) is described in Wang et al. (2024) (https://doi.org/10.1016/j.epsl.2024.118919), and the VELMAP codes are available at: https://github.com/nerc-comet/velmap.\n\nIf you are interested in a more developed version of the bayesian inversion, have a look at both Hussain et al. (2016) and the GBIS inversion software, for interseismic and coseismic deformation, respectively:\nhttps://comet.nerc.ac.uk/gbis/\n\nIf you found any issues in this practical, please log them under \"issues\" on the github repository.\n\n[Andrew Watson](https://github.com/andwatson), [Qi Ou](https://environment.leeds.ac.uk/see/staff/11006/dr-qi-ou), [John Condon](https://www.linkedin.com/in/john-condon-216268134/?originalSubdomain=uk) - 2024\n\nPresenter: Dehua Wang (E-mail: eedwa@leeds.ac.uk), University of Leeds","metadata":{}},{"id":"dca86a42","cell_type":"markdown","source":"### References\n\nElliott, J. (2009). Strain accumulation & release on the Tibetan Plateau measured using InSAR (Doctoral dissertation, Oxford University).\n\nHussain, E., Wright, T. J., Walters, R. J., Bekaert, D., Hooper, A., & Houseman, G. A. (2016). Geodetic observations of postseismic creep in the decade after the 1999 Izmit earthquake, Turkey: Implications for a shallow slip deficit. Journal of Geophysical Research: Solid Earth, 121(4), 2980-3001.\n\nWatson, A. R., Elliott, J. R., & Walters, R. J. (2022). Interseismic strain accumulation across the Main Recent Fault, SW Iran, from Sentinel-1 InSAR observations. Journal of Geophysical Research: Solid Earth, 127, e2021JB022674. \n\nOu, Q., Daout, S., Weiss, J. R., Shen, L., Lazecký, M., Wright, T. J., & Parsons, B. E. (2022). Large‐Scale Interseismic Strain Mapping of the NE Tibetan Plateau From Sentinel‐1 Interferometry. Journal of Geophysical Research: Solid Earth, 127(6), e2022JB024176.\n\nSavage, J. C., & Burford, R. O. (1973). Geodetic determination of relative plate motion in central California. Journal of Geophysical Research, 78(5), 832-845.\n\nVernant, P. (2015). What can we learn from 20 years of interseismic GPS measurements across strike-slip faults?. Tectonophysics, 644, 22-39.\n\nWeiss, J. R., et al. (2020). High‐resolution surface velocities and strain for Anatolia from Sentinel‐1 InSAR and GNSS data. Geophysical Research Letters, 47(17), e2020GL087376.\n\nWang, D., Elliott, J. R., Zheng, G., Wright, T. J., Watson, A. R., McGrath, J. D. (2024). Deciphering interseismic strain accumulation and its termination on the central-eastern Altyn Tagh fault from high-resolution velocity fields. Earth and Planetary Science Letters, 644, 118919.","metadata":{}},{"id":"97bab76c","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}